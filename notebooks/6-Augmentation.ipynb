{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d0f19e-7ebb-461a-8bd2-7ede7b190934",
   "metadata": {},
   "source": [
    "### `Step-6` : Image Augmentation\n",
    "- After completing some preprocessing steps in PySpark on Ubuntu, I downloaded the image dataset—consisting of around 1,000 images across 8 classes—from the HDFS system to my local disk. I then transferred the dataset from Ubuntu to Windows for the next phase. In this step, I planned to apply data augmentation techniques to simulate real-life challenges for the model. However, before augmentation, I decided to perform the annotation (labeling) process first. In object detection tasks, proper annotation significantly contributes to the model’s performance and learning. While annotation can also be done after augmentation, doing so would have resulted in around 2,000 images to label, which would be very time-consuming. Therefore, I chose to manually annotate the initial 1,000 images before applying augmentation.\n",
    "- For annotation (labeling), I used Label Studio, a powerful and user-friendly tool that supports various annotation formats, including the YOLO format. It was particularly helpful for creating accurate bounding boxes for object detection tasks. The following commands were used to install and launch Label Studio via the Anaconda Prompt:\n",
    "  - pip install label-studio\n",
    "  - label-studio start\n",
    "    \n",
    "- After manually labeling all images, I downloaded the dataset in YOLO format to prepare for the training phase. The downloaded folder contains four main components: Images, Labels, Classes and JSON file ( not required for training). Each image has a corresponding label file with the same name. The YOLO label format includes:\n",
    "\n",
    "`class_id`\tRrepresenting the class (e.g., 0 for bear, 1 for crocodile, etc.)\n",
    "\n",
    "`x_center`\tHorizontal center of the bounding box (relative to image width)\n",
    "\n",
    "`y_center`\tVertical center of the bounding box (relative to image height)\n",
    "\n",
    "`width`\t    Width of the bounding box (relative to image width)\n",
    "\n",
    "`height`\tHeight of the bounding box (relative to image height)\n",
    "\n",
    "All values are normalized (scaled between 0 and 1) with respect to the image size.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3799b0-6937-4842-b045-ef0bfdaedb6a",
   "metadata": {},
   "source": [
    "- There is only one step left before model training which is augmentation. I applied four different augmentation method :\n",
    "  - `180 degree rotation :` I created 200 randomly selected images from the raw dataset and applied a 180-degree rotation to each. One of the challenging aspects of this step was updating the corresponding label files, as the bounding box coordinates change after rotation. For 180-degree rotation, I was able to successfully generate new label coordinates by adjusting the YOLO format values accordingly.I initially attempted 90 and 270-degree rotations as well, but I faced difficulties in recalculating the correct label coordinates for those angles. As a result, I decided to proceed only with 180-degree rotated images to ensure annotation accuracy.\n",
    "  - `Blurring :` I applied strong Gaussian blur to 200 randomly selected images from the dataset. The goal of this augmentation step was to train the model to detect objects even when they appear with low pixel clarity, simulating real-world scenarios such poor camera focus. Since the structure and position of objects in the images remain unchanged, this process did not require recalculating or modifying the label coordinates.\n",
    "  - `Brightness and Contrast :` I applied strong brightness and contrast adjustments to 200 randomly selected images from the dataset. The goal of this augmentation step was to train the model to effectively detect objects under varying lighting conditions, such as overly bright or dim environments. Since these adjustments do not alter the position or shape of the objects, the original label coordinates remained valid and did not require any modification.\n",
    "  - `Motion Blur` I applied a strong motion blur kernel to 200 randomly selected images from the dataset. The aim of this augmentation was to train the model to detect objects accurately in scenarios where either the camera or the object is in motion. This helps improve the model’s robustness in real-time applications, especially when dealing with moving subjects. Since motion blur does not change the object’s position or size, the original label coordinates remained valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32623d82-6f1f-439f-a4bd-103f42eaeeb0",
   "metadata": {},
   "source": [
    "### Augmentation for 180 degree rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bba71a-e8ec-403e-a576-f5ca7857afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Paths\n",
    "INPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo\"  # Original dataset folder\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo_rotation\"  # Augmented dataset folder\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Rotation function with YOLO label correction\n",
    "def rotate_image_and_labels(image, labels, angle):\n",
    "    if angle == 180:\n",
    "        image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "        new_img_height, new_img_width = image.shape[:2]\n",
    "\n",
    "        new_labels = []\n",
    "        for cls_id, x_center, y_center, w, h in labels:\n",
    "            new_x = 1 - x_center\n",
    "            new_y = 1 - y_center\n",
    "            new_w = w\n",
    "            new_h = h\n",
    "\n",
    "            # Convert to pixel values\n",
    "            x_pixel = new_x * new_img_width\n",
    "            y_pixel = new_y * new_img_height\n",
    "            w_pixel = new_w * new_img_width\n",
    "            h_pixel = new_h * new_img_height\n",
    "\n",
    "            # Convert back to normalized values\n",
    "            new_x = x_pixel / new_img_width\n",
    "            new_y = y_pixel / new_img_height\n",
    "            new_w = w_pixel / new_img_width\n",
    "            new_h = h_pixel / new_img_height\n",
    "\n",
    "            # Keep within valid range\n",
    "            new_x = max(0, min(1, new_x))\n",
    "            new_y = max(0, min(1, new_y))\n",
    "            new_w = max(0, min(1, new_w))\n",
    "            new_h = max(0, min(1, new_h))\n",
    "\n",
    "            new_labels.append([cls_id, new_x, new_y, new_w, new_h])\n",
    "\n",
    "        return image, new_labels\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "# Process Images and Labels\n",
    "image_paths = glob(os.path.join(INPUT_FOLDER, '**/*.jpg'), recursive=True)\n",
    "selected_images = random.sample(image_paths, 200)  # Select 200 random images\n",
    "\n",
    "for img_path in selected_images:\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Load corresponding YOLO label file\n",
    "    label_path = img_path.replace('.jpg', '.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = []\n",
    "        for line in file.readlines():\n",
    "            values = line.strip().split()\n",
    "            if len(values) == 5:\n",
    "                labels.append(list(map(float, values)))\n",
    "\n",
    "    if not labels:\n",
    "        continue\n",
    "\n",
    "    # Rotate by 180 degrees only\n",
    "    rotated_img, rotated_labels = rotate_image_and_labels(img, labels, 180)\n",
    "\n",
    "    # Save Augmented Image and Labels with modified names\n",
    "    relative_path = os.path.relpath(img_path, INPUT_FOLDER)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    aug_img_path = os.path.join(OUTPUT_FOLDER, os.path.dirname(relative_path), f\"{base_name}_rotated(180).jpg\")\n",
    "    aug_label_path = aug_img_path.replace('.jpg', '.txt')\n",
    "\n",
    "    os.makedirs(os.path.dirname(aug_img_path), exist_ok=True)\n",
    "    cv2.imwrite(aug_img_path, rotated_img)\n",
    "\n",
    "    with open(aug_label_path, 'w') as file:\n",
    "        for label in rotated_labels:\n",
    "            file.write(f\"{int(label[0])} {label[1]:.15f} {label[2]:.15f} {label[3]:.15f} {label[4]:.15f}\\n\")\n",
    "\n",
    "print(\"✅ 180-degree rotation complete! 200 images successfully rotated and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78476681-6bdf-4dab-97a3-494122321d7f",
   "metadata": {},
   "source": [
    "### Augmentation for Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf91b5-3fbf-43e0-abf2-dc855b178218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "INPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo\"  # Original dataset folder\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo_blur\"  # Augmented dataset folder\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Blurring function\n",
    "def apply_blur(image):\n",
    "    # Apply very strong Gaussian blur with even larger kernel sizes (21, 25, 31)\n",
    "    kernel_size = random.choice([21, 25, 31])\n",
    "    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    return blurred_image\n",
    "\n",
    "# Process Images and Labels\n",
    "image_paths = glob(os.path.join(INPUT_FOLDER, '**/*.jpg'), recursive=True)\n",
    "selected_images = random.sample(image_paths, 200)  # Select 200 random images\n",
    "\n",
    "for img_path in selected_images:\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Load corresponding YOLO label file\n",
    "    label_path = img_path.replace('.jpg', '.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = []\n",
    "        for line in file.readlines():\n",
    "            values = line.strip().split()\n",
    "            if len(values) == 5:\n",
    "                labels.append(list(map(float, values)))\n",
    "\n",
    "    if not labels:\n",
    "        continue\n",
    "\n",
    "    # ✅ Apply extra-strong blurring augmentation\n",
    "    blurred_img = apply_blur(img)\n",
    "\n",
    "    # Save Augmented Image and Labels with modified names\n",
    "    relative_path = os.path.relpath(img_path, INPUT_FOLDER)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    aug_img_path = os.path.join(OUTPUT_FOLDER, os.path.dirname(relative_path), f\"{base_name}_blurred.jpg\")\n",
    "    aug_label_path = aug_img_path.replace('.jpg', '.txt')\n",
    "\n",
    "    os.makedirs(os.path.dirname(aug_img_path), exist_ok=True)\n",
    "    cv2.imwrite(aug_img_path, blurred_img)\n",
    "\n",
    "    with open(aug_label_path, 'w') as file:\n",
    "        for label in labels:\n",
    "            file.write(f\"{int(label[0])} {label[1]:.15f} {label[2]:.15f} {label[3]:.15f} {label[4]:.15f}\\n\")\n",
    "\n",
    "print(\"✅ Extra-strong blurring augmentation complete! 200 images successfully blurred and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca514331-3f65-4cb9-a892-58ff43375782",
   "metadata": {},
   "source": [
    "### Augmentation for Brightness and Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e893546-50df-4aba-8e6e-96a035b99a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "INPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo\"  # Original dataset folder\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo_bright_and_contr\"  # Augmented dataset folder\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Brightness and Contrast adjustment function\n",
    "def adjust_brightness_contrast(image):\n",
    "    # Stronger brightness and contrast adjustment\n",
    "    alpha = random.uniform(0.2, 3.0)  # Contrast control (0.2–3.0)\n",
    "    beta = random.randint(-100, 100)   # Brightness control (-100 to 100)\n",
    "    adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted\n",
    "\n",
    "# Process Images and Labels\n",
    "image_paths = glob(os.path.join(INPUT_FOLDER, '**/*.jpg'), recursive=True)\n",
    "selected_images = random.sample(image_paths, 200)  # Select 200 random images\n",
    "\n",
    "for img_path in selected_images:\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Load corresponding YOLO label file\n",
    "    label_path = img_path.replace('.jpg', '.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = []\n",
    "        for line in file.readlines():\n",
    "            values = line.strip().split()\n",
    "            if len(values) == 5:\n",
    "                labels.append(list(map(float, values)))\n",
    "\n",
    "    if not labels:\n",
    "        continue\n",
    "\n",
    "    # ✅ Apply stronger brightness and contrast adjustment\n",
    "    adjusted_img = adjust_brightness_contrast(img)\n",
    "\n",
    "    # Save Augmented Image and Labels with modified names\n",
    "    relative_path = os.path.relpath(img_path, INPUT_FOLDER)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    aug_img_path = os.path.join(OUTPUT_FOLDER, os.path.dirname(relative_path), f\"{base_name}_bright_contrast.jpg\")\n",
    "    aug_label_path = aug_img_path.replace('.jpg', '.txt')\n",
    "\n",
    "    os.makedirs(os.path.dirname(aug_img_path), exist_ok=True)\n",
    "    cv2.imwrite(aug_img_path, adjusted_img)\n",
    "\n",
    "    with open(aug_label_path, 'w') as file:\n",
    "        for label in labels:\n",
    "            file.write(f\"{int(label[0])} {label[1]:.15f} {label[2]:.15f} {label[3]:.15f} {label[4]:.15f}\\n\")\n",
    "\n",
    "print(\"✅ Strong brightness and contrast augmentation complete! 200 images successfully adjusted and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8f9d9-e8f4-411c-b692-1203e0fa10d9",
   "metadata": {},
   "source": [
    "### Augmentation for Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962af369-32d6-4db1-ae9f-1bcc838a9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "INPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo\"  # Original dataset folder\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\mesut\\Desktop\\yolo_motion_blur\"  # Augmented dataset folder\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Moderate Motion Blur function\n",
    "def apply_motion_blur(image):\n",
    "    # Moderate motion blur with smaller kernel sizes\n",
    "    kernel_size = random.choice([15, 20, 25])  # Reduced kernel size for softer blur\n",
    "    angle = random.choice([0, 45, 90, 135])  # Horizontal, vertical, and diagonal motion blur\n",
    "\n",
    "    # Create motion blur kernel\n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "    if angle == 0:  # Horizontal motion blur\n",
    "        kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "    elif angle == 90:  # Vertical motion blur\n",
    "        kernel[:, int((kernel_size - 1) / 2)] = np.ones(kernel_size)\n",
    "    elif angle == 45:  # Diagonal motion blur (top-left to bottom-right)\n",
    "        np.fill_diagonal(kernel, 1)\n",
    "    elif angle == 135:  # Diagonal motion blur (top-right to bottom-left)\n",
    "        np.fill_diagonal(np.fliplr(kernel), 1)\n",
    "\n",
    "    kernel = kernel / kernel_size\n",
    "\n",
    "    # Apply motion blur\n",
    "    motion_blurred = cv2.filter2D(image, -1, kernel)\n",
    "    return motion_blurred\n",
    "\n",
    "# Process Images and Labels\n",
    "image_paths = glob(os.path.join(INPUT_FOLDER, '**/*.jpg'), recursive=True)\n",
    "selected_images = random.sample(image_paths, 200)  # Select 200 random images\n",
    "\n",
    "for img_path in selected_images:\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Load corresponding YOLO label file\n",
    "    label_path = img_path.replace('.jpg', '.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = []\n",
    "        for line in file.readlines():\n",
    "            values = line.strip().split()\n",
    "            if len(values) == 5:\n",
    "                labels.append(list(map(float, values)))\n",
    "\n",
    "    if not labels:\n",
    "        continue\n",
    "\n",
    "    # ✅ Apply moderate motion blur augmentation\n",
    "    motion_blurred_img = apply_motion_blur(img)\n",
    "\n",
    "    # Save Augmented Image and Labels with modified names\n",
    "    relative_path = os.path.relpath(img_path, INPUT_FOLDER)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    aug_img_path = os.path.join(OUTPUT_FOLDER, os.path.dirname(relative_path), f\"{base_name}_motion_blur.jpg\")\n",
    "    aug_label_path = aug_img_path.replace('.jpg', '.txt')\n",
    "\n",
    "    os.makedirs(os.path.dirname(aug_img_path), exist_ok=True)\n",
    "    cv2.imwrite(aug_img_path, motion_blurred_img)\n",
    "\n",
    "    with open(aug_label_path, 'w') as file:\n",
    "        for label in labels:\n",
    "            file.write(f\"{int(label[0])} {label[1]:.15f} {label[2]:.15f} {label[3]:.15f} {label[4]:.15f}\\n\")\n",
    "\n",
    "print(\"✅ Moderate motion blur augmentation complete! 200 images successfully blurred and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
